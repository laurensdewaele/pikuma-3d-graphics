This was pretty interesting.

To achieve a perspective projection,
We need a camera point,
and we need the frustrum.
And to implement, implementing the perspective divide,
seems to be enough.


Still seems a bit weird.
We're generating a cube, -1 to 1,
and projecting the points (given our 'eye' is 1 away from the display),
and when rendering the points, we're displacing them so they appear in the middle of the screen,
and we're making them 4x4 rects


Left handed vs right handed coordinate systems;

OpenGL: +Z towards the viewer, -Z away from the viewer,
DirectX: opposite (as with Pikuma)

For rotation,
we use the trig formulas, derived from going from alpha -> beta.
so we end up with the new coordinates:

x' = x * cos(beta) - y * sin(beta)
y' = y * cos(beta) + x * sin(beta)

Thing is, when rotating around an axis (x, y or z),
we can use the same formulas

This is kinda cool, however, it lags when I move my mouse.
Probably an SDL threading issue...

So how does it work?
Instead of updating the original cube points, with their new locations,
We just create a cube_rotation_angle that we increment slightly every frame.



